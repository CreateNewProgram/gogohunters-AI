import os
import io
import time
import requests
import numpy as np
from fastapi import FastAPI, WebSocket
from dotenv import load_dotenv
from pydub import AudioSegment
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
from google.generativeai import GenerativeModel, configure

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TYPECAST_API_KEY = os.getenv("TYPECAST_API_KEY")
TYPECAST_ACTOR_ID = os.getenv("TYPECAST_ACTOR_ID")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gemini ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
configure(api_key=GEMINI_API_KEY)
gemini = GenerativeModel("models/gemini-1.5-pro")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI ì•± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Whisper ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸŸ¡ Whisper ì´ˆê¸°í™” ì‹œì‘")
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
model_id = "openai/whisper-small"

print(f"ğŸŸ¡ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_id} (device={device})")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
).to(device)
processor = AutoProcessor.from_pretrained(model_id)
print("ğŸŸ¢ Whisper ë¡œë“œ ì™„ë£Œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")

    try:
        # 1. ë©”íƒ€ë°ì´í„° ìˆ˜ì‹ 
        json_meta = await websocket.receive_json()
        print("âœ… ë©”íƒ€ë°ì´í„° ìˆ˜ì‹ :", json_meta)

        # 2. ì˜¤ë””ì˜¤ ìˆ˜ì‹ 
        audio_binary = await websocket.receive_bytes()
        print(f"âœ… ì˜¤ë””ì˜¤ ìˆ˜ì‹  ì™„ë£Œ ({len(audio_binary)} bytes)")

        # 3. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
        audio = AudioSegment.from_file(io.BytesIO(audio_binary))
        audio = audio.set_frame_rate(16000).set_channels(1)
        samples = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0

        # 4. STT ì²˜ë¦¬
        print("ğŸŸ¡ Whisper STT ë³€í™˜ ì¤‘...")
        inputs = processor(samples, sampling_rate=16000, return_tensors="pt").to(device)
        forced_decoder_ids = processor.get_decoder_prompt_ids(language="ko", task="transcribe")
        with torch.no_grad():
            generated_ids = model.generate(inputs.input_features, forced_decoder_ids=forced_decoder_ids)
        transcribed_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        print(f"ğŸ“ STT ê²°ê³¼: {transcribed_text}")

        # 5. Gemini ì‘ë‹µ ìƒì„±
        print("ğŸŸ¡ Gemini ì‘ë‹µ ìƒì„± ì¤‘...")
        chat = gemini.start_chat(history=[])
        prompt = f"'{transcribed_text}' ë¼ëŠ” ë°œí™”ì— ëŒ€í•´ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜."
        gemini_response = chat.send_message(prompt)
        answer_text = gemini_response.text.strip()
        print(f"ğŸ“ Gemini ì‘ë‹µ: {answer_text}")

        # 6. Typecast TTS ìš”ì²­ (v2)
        print("ğŸŸ¡ Typecast TTS ìš”ì²­ ì¤‘...")
        tts_headers = {
            "Authorization": f"Bearer {TYPECAST_API_KEY}",
            "Content-Type": "application/json"
        }
        tts_payload = {
            "text": answer_text,
            "lang": "auto",
            "tts_mode": "actor",
            "actor_id": TYPECAST_ACTOR_ID,
            "model_version": "latest",
            "xapi_audio_format": "wav",
            "xapi_hd": True
        }

        tts_response = requests.post("https://typecast.ai/api/speak", headers=tts_headers, json=tts_payload)
        tts_response.raise_for_status()
        speak_v2_url = tts_response.json()["result"]["speak_v2_url"]
        print(f"ğŸŸ¢ TTS ìš”ì²­ ì™„ë£Œ: {speak_v2_url}")

        # 7. TTS ìƒíƒœ í™•ì¸
        max_retry = 20
        for i in range(max_retry):
            check = requests.get(speak_v2_url, headers=tts_headers)
            check.raise_for_status()
            result = check.json()["result"]
            status = result["status"]

            if status == "done":
                audio_url = result["audio_download_url"]
                print("ğŸŸ¢ ì˜¤ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ:", audio_url)
                break
            elif status == "failed":
                raise Exception("âŒ TTS ì‹¤íŒ¨")
            else:
                print(f"â³ TTS ëŒ€ê¸° ì¤‘... ({i+1}/{max_retry}) status={status}")
                time.sleep(1)
        else:
            raise TimeoutError("âŒ TTS ì‘ë‹µì´ ì œí•œ ì‹œê°„ ë‚´ ë„ì°©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 8. ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        audio_data = requests.get(audio_url)
        print(f"âœ… ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(audio_data.content)} bytes)")

        with open("typecast_api_result.wav", "wb") as f:
            f.write(audio_data.content)
        print("ğŸ“ ë””ë²„ê·¸ìš© ì˜¤ë””ì˜¤ ì €ì¥ ì™„ë£Œ: typecast_api_result.wav")

        # 9. ì‘ë‹µ ì „ì†¡ (JSON + WAV)
        response_meta = {
            "user_id": json_meta.get("user_id", "unknown"),
            "sequence": json_meta.get("sequence", 1),
            "timestamp": json_meta.get("timestamp", ""),
            "answer": answer_text
        }
        await websocket.send_json(response_meta)
        await websocket.send_bytes(audio_data.content)
        print("âœ… WebSocket ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
        await websocket.send_text("âŒ ì„œë²„ ì˜¤ë¥˜: " + str(e))

    finally:
        await websocket.close()
        print("ğŸ”´ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")

# cloudflared tunnel --url http://localhost:8090

# uvicorn typecast_api:app --port 8090