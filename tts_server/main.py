import os
import io
import time
import uuid
import json
import hashlib
import requests
import faiss
import fitz
import numpy as np
import torch
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
from pydub import AudioSegment
from faster_whisper import WhisperModel
from google.generativeai import GenerativeModel, configure
from sentence_transformers import SentenceTransformer
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TYPECAST_API_KEY = os.getenv("TYPECAST_API_KEY")
TYPECAST_ACTOR_ID = os.getenv("TYPECAST_ACTOR_ID")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gemini ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
configure(api_key=GEMINI_API_KEY)
gemini = GenerativeModel("models/gemini-2.5-flash-lite")
user_sessions = {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI ì•± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Faster-Whisper ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸŸ¡ Faster-Whisper ì´ˆê¸°í™” ì‹œì‘")
device = "cuda" if torch.cuda.is_available() else "cpu"
whisper_model = WhisperModel(
    model_size_or_path="small",
    device=device,
    compute_type="int8" if device == "cuda" else "float32"
)
print("ğŸŸ¢ Faster-Whisper ë¡œë“œ ì™„ë£Œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG ì„¤ì • (ê²½ë¡œ/íŒŒë¼ë¯¸í„°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PDF_DIR = Path("pdfs")
STORE_DIR = Path(".rag_store")
STORE_DIR.mkdir(parents=True, exist_ok=True)
INDEX_PATH = STORE_DIR / "faiss.index"
META_PATH = STORE_DIR / "meta.json"

EMBED_MODEL_NAME = "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
CHUNK_SIZE = 800
CHUNK_OVERLAP = 200
TOP_K = 5
MAX_CTX_CHARS = 2000

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_text_from_pdfs(pdf_dir_path="pdfs"):
    pdf_dir = Path(pdf_dir_path)
    docs = []
    if not pdf_dir.exists():
        print(f"âš ï¸ PDF ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {pdf_dir.resolve()}")
        return docs

    for pdf_file in pdf_dir.glob("*.pdf"):
        try:
            doc = fitz.open(pdf_file)
            text = ""
            for page in doc:
                text += page.get_text()
            docs.append({"filename": pdf_file.name, "content": text})
            doc.close()
        except Exception as e:
            print(f"âš ï¸ PDF íŒŒì‹± ì‹¤íŒ¨: {pdf_file.name} - {e}")
    return docs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸: í…ìŠ¤íŠ¸ ì²­í‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def chunk_text(text, chunk_size=800, overlap=200):
    chunks = []
    n = len(text)
    if n == 0:
        return chunks
    start = 0
    while start < n:
        end = min(start + chunk_size, n)
        chunks.append(text[start:end])
        if end >= n:
            break
        start = max(0, end - overlap)
    return chunks

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸: ì½”í¼ìŠ¤ ì§€ë¬¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_corpus_fingerprint(pdf_dir: Path) -> str:
    """íŒŒì¼ëª…, í¬ê¸°, ìˆ˜ì •ì‹œê°„ìœ¼ë¡œ í•´ì‹œ ìƒì„± (ë‚´ìš© ë³€ê²½ ê°ì§€)"""
    h = hashlib.sha256()
    if not pdf_dir.exists():
        return h.hexdigest()
    for p in sorted(pdf_dir.glob("*.pdf")):
        stat = p.stat()
        h.update(p.name.encode("utf-8"))
        h.update(str(stat.st_size).encode("utf-8"))
        h.update(str(int(stat.st_mtime)).encode("utf-8"))
    return h.hexdigest()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¸ë±ìŠ¤ ì €ì¥/ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_index(index, chunks_meta, fingerprint: str, params: dict):
    faiss.write_index(index, str(INDEX_PATH))
    meta = {
        "fingerprint": fingerprint,
        "chunks_meta": chunks_meta,
        "params": params,
    }
    META_PATH.write_text(json.dumps(meta, ensure_ascii=False), encoding="utf-8")
    print("ğŸ’¾ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ")

def load_index():
    if not INDEX_PATH.exists() or not META_PATH.exists():
        return None, None, None, None
    try:
        index = faiss.read_index(str(INDEX_PATH))
        meta = json.loads(META_PATH.read_text(encoding="utf-8"))
        chunks_meta = meta.get("chunks_meta", [])
        fingerprint = meta.get("fingerprint")
        params = meta.get("params", {})
        return index, chunks_meta, fingerprint, params
    except Exception as e:
        print("âš ï¸ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨:", e)
        return None, None, None, None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FAISS ë¹Œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_faiss_index(docs, model, chunk_size=800, overlap=200):
    """
    ë°˜í™˜:
      index: FAISS IndexFlatL2
      chunks_meta: [{doc_id, filename, text}]
      embeddings: np.ndarray (num_chunks, dim)
    """
    chunks_meta = []
    for i, doc in enumerate(docs):
        for ch in chunk_text(doc["content"], chunk_size=chunk_size, overlap=overlap):
            if ch.strip():
                chunks_meta.append({"doc_id": i, "filename": doc["filename"], "text": ch})

    if not chunks_meta:
        # ë¹ˆ ì¸ë±ìŠ¤ ë°©ì§€: ì°¨ì› ì•Œì•„ë‚´ë ¤ë©´ dummy ì„ë² ë”©
        dummy_vec = model.encode([" "], convert_to_numpy=True)
        dim = dummy_vec.shape[1]
        index = faiss.IndexFlatL2(dim)
        return index, [], np.zeros((0, dim), dtype=np.float32)

    texts = [c["text"] for c in chunks_meta]
    embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings.astype(np.float32))
    return index, chunks_meta, embeddings

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_similar_docs(query, index, chunks_meta, model, top_k=5, max_total_chars=2000):
    if not chunks_meta:
        return ""
    query_emb = model.encode([query], convert_to_numpy=True)
    D, I = index.search(query_emb, top_k)

    picked, total_len = [], 0
    for idx in I[0]:
        c = chunks_meta[int(idx)]
        snippet = c["text"].strip()
        add_len = len(snippet)
        if total_len + add_len > max_total_chars:
            snippet = snippet[: max(0, max_total_chars - total_len)]
        picked.append(f"[{c['filename']}] {snippet}")
        total_len += len(snippet)
        if total_len >= max_total_chars:
            break
    return "\n\n".join(picked)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gemini RAG ì‘ë‹µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_with_context(user_input, context_text):
    prompt = f"""
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤. ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
----- ì°¸ê³  ë¬¸ì„œ -----
{context_text}
---------------------
ì§ˆë¬¸: {user_input}
ì•„ì´ë“¤ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ 100ì ì´ë‚´ë¡œ ì‰½ê³  ì •í™•í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
"""
    response = gemini.generate_content(prompt)
    return response.text.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG ì´ˆê¸°í™” (ìºì‹œ ì‚¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_rag(force_rebuild: bool = False):
    print("ğŸŸ¡ RAG ì´ˆê¸°í™” ì‹œì‘")
    current_fp = compute_corpus_fingerprint(PDF_DIR)

    # ìºì‹œ ë¡œë“œ ì‹œë„
    if not force_rebuild:
        cached = load_index()
    else:
        cached = (None, None, None, None)

    # ìºì‹œ ìœ íš¨ì„± í™•ì¸
    if cached and all(cached[:3]):
        cached_index, cached_chunks, cached_fp, cached_params = cached
        # íŒŒë¼ë¯¸í„°/ëª¨ë¸/ì½”í¼ìŠ¤ ì§€ë¬¸ ì¼ì¹˜ í™•ì¸
        if (
            cached_fp == current_fp
            and cached_params
            and cached_params.get("embed_model_name") == EMBED_MODEL_NAME
            and cached_params.get("chunk_size") == CHUNK_SIZE
            and cached_params.get("chunk_overlap") == CHUNK_OVERLAP
        ):
            print(f"âœ… ìºì‹œ ì ì¤‘: ì²­í¬ {len(cached_chunks)}ê°œ, ì¸ë±ìŠ¤ ì¬ì‚¬ìš©")
            return cached_index, cached_chunks

    # ì¬ë¹Œë“œ
    print("ğŸ”„ ì¸ë±ìŠ¤ ì¬ë¹Œë“œ (ë¬¸ì„œ ë³€ê²½/íŒŒë¼ë¯¸í„° ë³€ê²½/ìºì‹œ ì—†ìŒ)")
    docs = extract_text_from_pdfs(str(PDF_DIR))
    model = SentenceTransformer(EMBED_MODEL_NAME)
    index, chunks_meta, _ = build_faiss_index(
        docs, model, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP
    )

    params = {
        "embed_model_name": EMBED_MODEL_NAME,
        "chunk_size": CHUNK_SIZE,
        "chunk_overlap": CHUNK_OVERLAP,
        "top_k": TOP_K,
        "max_ctx_chars": MAX_CTX_CHARS,
    }
    save_index(index, chunks_meta, current_fp, params)
    print(f"ğŸŸ¢ RAG ë¡œë“œ ì™„ë£Œ (ë¬¸ì„œ {len(docs)}ê°œ, ì²­í¬ {len(chunks_meta)}ê°œ)")
    return index, chunks_meta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì „ì—­ RAG í•¸ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì£¼ì˜: ê²€ìƒ‰ ë•Œ ì“¸ SentenceTransformer ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ(ë©”ëª¨ë¦¬ ìƒì£¼)
rag_model = SentenceTransformer(EMBED_MODEL_NAME)
faiss_index, chunks_meta = init_rag(force_rebuild=False)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨")

    user_id = str(uuid.uuid4())
    chat = gemini.start_chat(history=[])
    user_sessions[user_id] = chat
    print(f"ğŸŸ¢ Gemini ì„¸ì…˜ ìƒì„±ë¨: {user_id}")

    try:
        while True:
            try:
                # ğŸ§ ì˜¤ë””ì˜¤ ìˆ˜ì‹ 
                audio_binary = await websocket.receive_bytes()
                print(f"ğŸ§ ì˜¤ë””ì˜¤ ìˆ˜ì‹  ({len(audio_binary)} bytes)")

                # ğŸ”Š STT ì „ì²˜ë¦¬
                audio = AudioSegment.from_file(io.BytesIO(audio_binary))
                audio = audio.set_frame_rate(16000).set_channels(1)
                audio_path = "temp_audio.wav"
                audio.export(audio_path, format="wav")

                segments, _ = whisper_model.transcribe(audio_path, language="ko", beam_size=1)
                transcribed_text = "".join([seg.text for seg in segments]).strip()
                print(f"ğŸ“ STT ê²°ê³¼: {transcribed_text}")

                # ğŸ’¬ Gemini RAG: ê²€ìƒ‰ â†’ ì‘ë‹µ
                context_text = search_similar_docs(
                    transcribed_text, faiss_index, chunks_meta, rag_model, top_k=TOP_K, max_total_chars=MAX_CTX_CHARS
                )
                answer_text = ask_with_context(transcribed_text, context_text)
                print(f"ğŸ¤– Gemini ì‘ë‹µ: {answer_text}")

                # ğŸ—£ï¸ Typecast TTS ìš”ì²­
                tts_headers = {
                    "Authorization": f"Bearer {TYPECAST_API_KEY}",
                    "Content-Type": "application/json"
                }
                tts_payload = {
                    "text": answer_text[:500],
                    "lang": "ko-kr",
                    "tts_mode": "actor",
                    "actor_id": TYPECAST_ACTOR_ID,
                    "model_version": "latest",
                    "xapi_audio_format": "wav",
                    "xapi_hd": True,
                    "volume": 100,
                    "speed_x": 1,
                    "tempo": 1,
                    "pitch": 0
                }

                tts_response = requests.post("https://typecast.ai/api/speak", headers=tts_headers, json=tts_payload)

                # ì˜ˆì™¸ ì²˜ë¦¬
                if tts_response.status_code == 400:
                    print(f"âŒ [400 Bad Request] ì‘ë‹µ: {tts_response.text}")
                    raise Exception("TTS ìš”ì²­ì— í•„ìš”í•œ íŒŒë¼ë¯¸í„°ê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
                elif tts_response.status_code == 401:
                    print(f"âŒ [401 Unauthorized] ì‘ë‹µ: {tts_response.text}")
                    raise Exception("TTS ì¸ì¦ ì‹¤íŒ¨: API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                elif tts_response.status_code == 429:
                    print(f"âŒ [429 Too Many Requests] ì‘ë‹µ: {tts_response.text}")
                    raise Exception("TTS ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                elif not tts_response.ok:
                    print(f"âŒ [TTS ìš”ì²­ ì‹¤íŒ¨] ìƒíƒœ ì½”ë“œ: {tts_response.status_code}, ì‘ë‹µ: {tts_response.text}")
                    raise Exception(f"TTS ìš”ì²­ ì‹¤íŒ¨: {tts_response.status_code}")

                speak_v2_url = tts_response.json()["result"]["speak_v2_url"]

                # ìƒíƒœ í´ë§
                audio_url = None
                for _ in range(20):
                    check = requests.get(speak_v2_url, headers=tts_headers)
                    result = check.json()["result"]
                    status = result["status"]
                    if status == "done":
                        audio_url = result["audio_download_url"]
                        break
                    elif status == "failed":
                        raise Exception("âŒ TTS ì²˜ë¦¬ ì‹¤íŒ¨")
                    time.sleep(1)
                else:
                    raise TimeoutError("âŒ TTS ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼")

                audio_data = requests.get(audio_url).content

                # ğŸ“¤ ì‘ë‹µ ì „ì†¡
                await websocket.send_json({
                    "user_id": user_id,
                    "text": transcribed_text,
                    "answer": answer_text,
                    "timestamp": time.time()
                })
                await websocket.send_bytes(audio_data)
                print("âœ… ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")

            except WebSocketDisconnect:
                print("ğŸ”´ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œë¨ (WebSocketDisconnect)")
                break

            except Exception as e_inner:
                print(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_inner}")
                if websocket.client_state.name == "CONNECTED":
                    try:
                        await websocket.send_text("âŒ ì˜¤ë¥˜: " + str(e_inner))
                    except Exception as send_fail:
                        print(f"âŒ ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {send_fail}")
                break

    finally:
        if websocket.client_state.name != "DISCONNECTED":
            try:
                await websocket.close()
                print("ğŸ”’ WebSocket ë‹«í˜")
            except Exception as close_error:
                print(f"âš ï¸ WebSocket ì¢…ë£Œ ì‹¤íŒ¨: {close_error}")

        print("ğŸ§¹ ì„¸ì…˜ ì¢…ë£Œ:", user_id)
        user_sessions.pop(user_id, None)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/sessions")
async def sessions(request: Request):
    user_id = request.query_params.get("user_id")
    if user_id is None:
        return JSONResponse(content={
            "active_sessions_count": len(user_sessions),
            "user_ids": list(user_sessions.keys())
        })

    session = user_sessions.get(user_id)
    if session is None:
        return JSONResponse(status_code=404, content={"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

    try:
        history = []
        for item in session.history:
            role = getattr(item, "role", "unknown")
            content = (
                "\n".join(str(p) for p in item.parts)
                if hasattr(item, "parts") and isinstance(item.parts, list)
                else str(getattr(item, "parts", "ë‚´ìš© ì—†ìŒ"))
            )
            history.append({"role": role, "content": content})
        return JSONResponse(content={
            "user_id": user_id,
            "message_count": len(history),
            "chat_history": history
        })
    except Exception as e:
        return JSONResponse(status_code=500, content={
            "error": "íˆìŠ¤í† ë¦¬ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "details": str(e)
        })

# ì‹¤í–‰ ëª…ë ¹ ì˜ˆì‹œ
# uvicorn main:app --reload --port 8090
# cloudflared tunnel --url http://localhost:8090
